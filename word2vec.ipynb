{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word2vec.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPQQVhCcfoKUJEIRGyiMbQT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grtushar/word2vec/blob/main/word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwGIiqL1QJnW"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DVZVqnq6cgJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34768f43-f1cd-407e-9229-ccd249b95660"
      },
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords \n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from numpy.lib.function_base import vectorize"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VChYHZq1XZUQ"
      },
      "source": [
        "# Cleaning Special Characters and Removing Punctuations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC9pVDCjDDXw"
      },
      "source": [
        "# Some preprocesssing that will be common to all the text classification methods you will see.\n",
        "\n",
        "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£',\n",
        " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…',\n",
        " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─',\n",
        " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞',\n",
        " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
        "\n",
        "def clean_text(x):\n",
        "    x = str(x)\n",
        "    for punct in puncts:\n",
        "        if punct in x:\n",
        "            x = x.replace(punct, f' {punct} ')\n",
        "    return x"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeM2-W6uXtJ3"
      },
      "source": [
        "# Cleaning Numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HWRYqi_Xxqr"
      },
      "source": [
        "def clean_numbers(x):\n",
        "    if bool(re.search(r'\\d', x)):\n",
        "        x = re.sub('[0-9]{5,}', '#####', x)\n",
        "        x = re.sub('[0-9]{4}', '####', x)\n",
        "        x = re.sub('[0-9]{3}', '###', x)\n",
        "        x = re.sub('[0-9]{2}', '##', x)\n",
        "    return x"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP8FvrV5HVLH"
      },
      "source": [
        "# Removing Contractions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0apuMb-pGwzR"
      },
      "source": [
        "contraction_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\n",
        "\n",
        "def _get_contractions(contraction_dict):\n",
        "    contraction_re = re.compile('(%s)' % '|'.join(contraction_dict.keys()))\n",
        "    return contraction_dict, contraction_re\n",
        "\n",
        "contractions, contractions_re = _get_contractions(contraction_dict)\n",
        "\n",
        "def replace_contractions(text):\n",
        "    def replace(match):\n",
        "        return contractions[match.group(0)]\n",
        "    return contractions_re.sub(replace, text)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrNUyZCLPumU"
      },
      "source": [
        "# Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxt8Vfn8xPzv"
      },
      "source": [
        "def get_corpus():\n",
        "  corpus_dir = './data/RNN/'\n",
        "  corpus_text_file = os.path.join(corpus_dir, 'en.wikipedia.2010.100K.txt')\n",
        "\n",
        "  if not os.path.isfile( corpus_text_file ):\n",
        "    if not os.path.exists(corpus_dir):\n",
        "        os.makedirs(corpus_dir)\n",
        "\n",
        "    corpus_text_tar = 'eng_wikipedia_2010_100K.tar.gz'    \n",
        "    download_url = 'http://pcai056.informatik.uni-leipzig.de/downloads/corpora/'+corpus_text_tar\n",
        "\n",
        "    data_cache = './data/cache'\n",
        "    if not os.path.exists(data_cache):\n",
        "        os.makedirs(data_cache)\n",
        "    \n",
        "    # Fall-back url if too slow\n",
        "    #download_url= 'http://redcatlabs.com/downloads/deep-learning-workshop/notebooks/data/RNN/'+corpus_text_tar\n",
        "\n",
        "    import shutil, requests\n",
        "\n",
        "    # Get the download path from the web-service\n",
        "    #urllib.request.urlretrieve('http://wortschatz.uni-leipzig.de/download/service', corpus_text_tar)\n",
        "    # download_url = ...\n",
        "    \n",
        "    tarfilepath = os.path.join(data_cache, corpus_text_tar)\n",
        "    if not os.path.isfile( tarfilepath ):\n",
        "        response = requests.get(download_url, stream=True)\n",
        "        with open(tarfilepath, 'wb') as out_file:\n",
        "            shutil.copyfileobj(response.raw, out_file)\n",
        "    if os.path.isfile(tarfilepath):\n",
        "        import tarfile\n",
        "        #tarfile.open(tarfilepath, 'r:gz').extractall(corpus_dir)\n",
        "        tarfile.open(tarfilepath, 'r:gz').extract('eng_wikipedia_2010_100K-sentences.txt', corpus_dir)\n",
        "    shutil.move(os.path.join(corpus_dir, 'eng_wikipedia_2010_100K-sentences.txt'), corpus_text_file)\n",
        "    \n",
        "    # Get rid of tarfile source (the required text file itself will remain)\n",
        "    #os.unlink(tarfilepath)\n",
        "\n",
        "  print(\"Corpus available locally\")\n",
        "\n",
        "  while True:\n",
        "    corpus = ''\n",
        "    number_of_lines = 0\n",
        "    with open(corpus_text_file, encoding='utf-8') as f:\n",
        "      for line in f.readlines():\n",
        "          n,l = line.split('\\t')   # Strip of the initial numbers\n",
        "          corpus += l\n",
        "          number_of_lines += 1\n",
        "          if(number_of_lines == 10):\n",
        "            return corpus\n",
        "  \n",
        "  return ''\n",
        "\n",
        "# Sample Input:\n",
        "# Sample Output:\n",
        "def word_to_one_hot_vector(word_idx, vocab_size):\n",
        "  one_hot_vector = np.zeros(vocab_size)\n",
        "  one_hot_vector[word_idx] = 1\n",
        "  return one_hot_vector\n",
        "\n",
        "# Sample Input:\n",
        "# Sample Output:\n",
        "def extract_vacoab_info(text):\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts([text])\n",
        "  return len(tokenizer.word_index), tokenizer.word_index, dict(map(reversed, tokenizer.word_index.items()))\n",
        "\n",
        "# Sample Input:\n",
        "# Sample Output:\n",
        "def split_sentence(corpus):\n",
        "    stop_words = set(stopwords.words('english'))    \n",
        "    training_data = []\n",
        "    sentences = corpus.split(\".\")\n",
        "    for i in range(len(sentences)):\n",
        "        sentences[i] = sentences[i].strip()\n",
        "        sentence = sentences[i].split()\n",
        "        x = [word.strip(string.punctuation) for word in sentence if word not in stop_words]\n",
        "        x = [word.lower() for word in x if word != '']\n",
        "        training_data.append(x)\n",
        "    return training_data\n",
        "\n",
        "# Sample Input:\n",
        "# Sample Output:\n",
        "def prepare_training_data(sentences, window_size, vocab, vocab_size):\n",
        "  training_data = []\n",
        "  for sentence in sentences:\n",
        "    sent_len = len(sentence)\n",
        "    for i, word in enumerate(sentence):\n",
        "      target_word = word_to_one_hot_vector(vocab[sentence[i]] - 1, vocab_size)\n",
        "      \n",
        "      word_context = []\n",
        "      for j in range(i - window_size, i + window_size+1):\n",
        "        if j != i and j <= sent_len-1 and j >= 0:\n",
        "          word_context.append(word_to_one_hot_vector(vocab[sentence[j]] - 1, vocab_size))\n",
        "      training_data.append([target_word, word_context])\n",
        "  return np.array(training_data)\n",
        "\n",
        "def plot_vectors(wordVectors=wordVectors):\n",
        "  visualizeWords = [\"the\", \"a\", \"that\", 'this', 'her', 'present', 'day', 'take', 'police', 'officers']\n",
        "  print(vocab)\n",
        "  visualizeIdx = [vocab[word] for word in visualizeWords]\n",
        "  visualizeVecs = wordVectors[visualizeIdx, :]\n",
        "  temp = (visualizeVecs - np.mean(visualizeVecs, axis=0))\n",
        "  covariance = 1.0 / len(visualizeIdx) * temp.T.dot(temp)\n",
        "  U,S,V = np.linalg.svd(covariance)\n",
        "  coord = temp.dot(U[:,0:2]) \n",
        "\n",
        "  for i in range(len(visualizeWords)):\n",
        "      plt.text(coord[i,0], coord[i,1], visualizeWords[i], bbox=dict(facecolor='green', alpha=0.1))\n",
        "      \n",
        "  plt.xlim((np.min(coord[:,0]), np.max(coord[:,0])))\n",
        "  plt.ylim((np.min(coord[:,1]), np.max(coord[:,1])))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9vmYZO6PjoA"
      },
      "source": [
        "# CBOW and Skip-gram Implementaion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qq7dDi6NMpWS"
      },
      "source": [
        "class word2Vec:\n",
        "  def __init__(self, window_size, vocab, vocab_size, idx2word, embedding_dim, word_context, target_word, model):\n",
        "    self.window_size = window_size\n",
        "    self.vocab = vocab\n",
        "    self.vocab_size = vocab_size\n",
        "    self.idx2word = idx2word\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.optimizer = tf.optimizers.SGD(learning_rate=0.1)\n",
        "    self.alpha = 0.1\n",
        "    self.model = model\n",
        "    self.__set_var_depending_on_model(word_context, target_word);\n",
        "\n",
        "  def __set_var_depending_on_model(self, word_context, target_word):\n",
        "    if(self.__is_cbow()):\n",
        "      self.X_train = word_context\n",
        "      self.y_train = target_word\n",
        "    else:\n",
        "      self.X_train = target_word\n",
        "      self.y_train = word_context\n",
        "\n",
        "  def __is_cbow(self):\n",
        "    return self.model == 'CBOW'\n",
        "\n",
        "  def train(self, epochs):\n",
        "    self.W1 = tf.Variable(tf.random.normal([self.vocab_size, self.embedding_dim]))\n",
        "    self.b1 = tf.Variable(tf.random.normal([self.embedding_dim])) #bias\n",
        "    self.W2 = tf.Variable(tf.random.normal([self.embedding_dim, self.vocab_size]))\n",
        "    self.b2 = tf.Variable(tf.random.normal([self.vocab_size]))\n",
        "\n",
        "    for _ in range(epochs):\n",
        "      with tf.GradientTape() as t:\n",
        "        hidden_layer = tf.add(tf.matmul(self.X_train,self.W1),self.b1)\n",
        "        output_layer = tf.nn.softmax(tf.add( tf.matmul(hidden_layer, self.W2), self.b2))\n",
        "        cross_entropy_loss = tf.reduce_mean(-tf.math.reduce_sum(self.y_train * tf.math.log(output_layer), axis=[1]))\n",
        "      grads = t.gradient(cross_entropy_loss, [self.W1, self.b1, self.W2, self.b2])\n",
        "      self.optimizer.apply_gradients(zip(grads,[self.W1, self.b1, self.W2, self.b2]))\n",
        "      if(_ % 1000 == 0):\n",
        "        print(cross_entropy_loss)\n",
        "\n",
        "  def train_using_numpy(self, epochs):\n",
        "    self.W1 = np.random.uniform(-0.8, 0.8, (self.vocab_size, self.embedding_dim))\n",
        "    self.W2 = np.random.uniform(-0.8, 0.8, (self.embedding_dim, self.vocab_size))\n",
        "    #self.b1 = np.random.uniform(-0.8, 0.8, self.embedding_dim) #np.zeros(self.embedding_dim)\n",
        "    #self.b2 = np.random.uniform(-0.8, 0.8, self.vocab_size) #np.zeros(self.vocab_size)\n",
        "\n",
        "    if(self.__is_cbow()):\n",
        "      self.__train_CBOW_model(epochs)\n",
        "    else:\n",
        "      self.__train_skip_gram_model(epochs)\n",
        "\n",
        "  def __train_CBOW_model(self, epochs):\n",
        "    for i in range(0, epochs):\n",
        "        self.loss = 0\n",
        "\n",
        "        for j in range(0, self.X_train.shape[0]):\n",
        "\n",
        "            x = np.mean(self.X_train[j], axis=0)\n",
        "\n",
        "            y_hat, z1, z2 = self.forward_pass(x)\n",
        "\n",
        "            EI = np.subtract(y_hat, self.y_train[j])\n",
        "\n",
        "            self.backprop(EI, z1, x)\n",
        "            \n",
        "            self.loss += -float(z2[self.y_train[j] == 1]) + np.log(np.sum(np.exp(z2)))\n",
        "            # self.loss += self.calculate_loss(y_hat, self.y_train[j])\n",
        "\n",
        "        if(i % 1000 == 0):\n",
        "          print('EPOCH:',i, 'LOSS:', self.loss)\n",
        "    pass\n",
        "\n",
        "  def __train_skip_gram_model(self, epochs):\n",
        "    for i in range(0, epochs):\n",
        "        self.loss = 0\n",
        "\n",
        "        for j in range(0, self.X_train.shape[0]):\n",
        "            x = self.X_train[j]\n",
        "\n",
        "            y_hat, z1, z2 = self.forward_pass(x)\n",
        "\n",
        "            EI = np.array([-label + y_hat.T for label in self.y_train[j]])\n",
        "\n",
        "            self.backprop(EI, z1, x)\n",
        "            \n",
        "            self.loss += -np.sum([z2[label == 1] for label in self.y_train[j]]) + len(self.y_train[j]) * np.log(np.sum(np.exp(z2)))\n",
        "            # self.loss += self.calculate_loss(y_hat, self.y_train[j])\n",
        "\n",
        "        if(i % 1000 == 0):\n",
        "          print('EPOCH:',i, 'LOSS:', self.loss)\n",
        "    pass\n",
        "\n",
        "  def calculate_loss(self, y_hat, y):\n",
        "    # Cross Entropy Loss\n",
        "    loss = -np.sum(y * np.log(y_hat))\n",
        "    return loss\n",
        "\n",
        "  # FORWARD PASS\n",
        "  def forward_pass(self, x):\n",
        "      z1 = np.dot(self.W1.T, x) # + self.b1\n",
        "      z2 = np.dot(self.W2.T, z1) # + self.b2\n",
        "      y_hat = self.softmax(z2)\n",
        "      return y_hat, z1, z2\n",
        "\n",
        "  # SOFTMAX ACTIVATION FUNCTION\n",
        "  def softmax(self, x):\n",
        "      e_x = np.exp(x - np.max(x))\n",
        "      return e_x / e_x.sum(axis=0)\n",
        "\n",
        "  # BACKPROPAGATION\n",
        "  def backprop(self, e, h, x):\n",
        "      if(self.__is_cbow()):\n",
        "        dl_dw2 = np.outer(h, e)  \n",
        "        dl_dw1 = np.outer(x, np.dot(self.W2, e.T))\n",
        "      else:\n",
        "        dl_dw2 = np.outer(h, np.sum(e, axis=0))\n",
        "        dl_dw1 = np.outer(x, np.dot(self.W2, np.sum(e, axis=0)))\n",
        "\n",
        "      # UPDATE WEIGHTS\n",
        "      self.W1 = self.W1 - (self.alpha * dl_dw1)\n",
        "      self.W2 = self.W2 - (self.alpha * dl_dw2)\n",
        "      pass\n",
        "\n",
        "  def get_vector_from_word(self, word):\n",
        "    return (self.W1)[self.vocab[word] - 1]\n",
        "\n",
        "  def vectorized(self, word_idx):\n",
        "    return (self.W1)[word_idx]\n",
        "\n",
        "  # calculate word1 + word2 - word3\n",
        "  def check_subtract_prop(self, word1, word2, word3):\n",
        "    vec1 = self.vectorized(self.vocab[word1] - 1)\n",
        "    vec2 = self.vectorized(self.vocab[word2] - 1)\n",
        "    vec3 = self.vectorized(self.vocab[word3] - 1)\n",
        "\n",
        "    res = vec1 + vec2 - vec3\n",
        "    closest_word_idx = -1\n",
        "    mn = 99999999\n",
        "    for i in range(self.vocab_size):\n",
        "      # ignore the words sent to this function\n",
        "      if(i == self.vocab[word1] - 1 or i == self.vocab[word2] - 1 or i == self.vocab[word3] - 1 ):\n",
        "        continue\n",
        "\n",
        "      dist = np.linalg.norm(res - self.vectorized(i))\n",
        "      if(mn > dist):\n",
        "        mn = dist\n",
        "        closest_word_idx = i\n",
        "    closest_word_idx += 1\n",
        "\n",
        "    return self.idx2word[closest_word_idx]\n",
        "\n",
        "  def word_with_closest_distance(self, word):\n",
        "    idx = self.vocab[word] - 1\n",
        "    vec = self.vectorized(idx)\n",
        "\n",
        "    closest_word_idx = -1\n",
        "    mn = 99999999\n",
        "    for i in range(self.vocab_size):\n",
        "      if(i == idx):\n",
        "        continue\n",
        "      dist = np.linalg.norm(vec - self.vectorized(i))\n",
        "      if(mn > dist):\n",
        "        mn = dist\n",
        "        closest_word_idx = i\n",
        "    closest_word_idx += 1\n",
        "\n",
        "    return self.idx2word[closest_word_idx]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXlSJtfnQPju"
      },
      "source": [
        "# Prepare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFHf6ifvGzdO",
        "outputId": "e2df1def-fa6e-4103-fd11-0b691adc8046"
      },
      "source": [
        "window_size = 3\n",
        "embedding_dim = 5\n",
        "epochs = 10000\n",
        "\n",
        "corpus = get_corpus() \n",
        "# corpus = 'Dhaka is the capital of Bangladesh. Delhi is the capital of India. Paris is the capital of France.'\n",
        "# print(\"Raw corpus: \", corpus)\n",
        "\n",
        "corpus = clean_text(corpus)\n",
        "# print(\"Corpus after cleaning: \", corpus)\n",
        "\n",
        "corpus = clean_numbers(corpus)\n",
        "# print(\"Corpus after cleaning numbers: \", corpus)\n",
        "\n",
        "corpus = replace_contractions(corpus)\n",
        "# print(\"Corpus after replacing contradictions: \", corpus)\n",
        "\n",
        "\n",
        "sentences = split_sentence(corpus)\n",
        "print(sentences)\n",
        "\n",
        "vocab_size, vocab, idx2word = extract_vacoab_info(corpus)\n",
        "print(\"Vocabulary size: \", vocab_size)\n",
        "print(\"Vocabulary\", vocab)\n",
        "print(\"Index to word dict\", idx2word)\n",
        "\n",
        "training_data = prepare_training_data(sentences, window_size, vocab, vocab_size)\n",
        "\n",
        "x_train = []\n",
        "y_train = []\n",
        "for y, x in training_data:\n",
        "  x_train.append(x)\n",
        "  y_train.append(y)\n",
        "\n",
        "# print(len(x_train))\n",
        "# print(len(x_train[3]))\n",
        "# print(x_train[3])\n",
        "\n",
        "x_train = np.asarray(x_train)\n",
        "y_train = np.asarray(y_train)\n",
        "\n",
        "# print(x_train)\n",
        "# print(y_train)\n",
        "\n",
        "w2v_cbow = word2Vec(window_size=window_size, vocab = vocab, vocab_size=vocab_size, idx2word=idx2word, embedding_dim=embedding_dim, word_context=x_train, target_word=y_train, model='CBOW')\n",
        "w2v_skip_gram = word2Vec(window_size=window_size, vocab = vocab, vocab_size=vocab_size, idx2word=idx2word, embedding_dim=embedding_dim, word_context=x_train, target_word=y_train, model='skip_gram')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus available locally\n",
            "[['showing', 'even', 'modern', 'warfare', 's', 's', 'dilapidated', 'fortifications', 'still', 'defensive', 'usefulness'], ['celtic', 'finally', 'cemented', 'permanent', 'home', 'would', 'see', 'huge', 'success', 'present', 'day'], ['he', 'gives', 'shuji', 'pills', 'saying', 'chise', 'needs', 'weapon', 'side', '’', 'take', 'later', 'gives', 'much', 'needed', 'maintenance'], ['in', 'areas', 'trio', 'called', 'trail', 'hand', 'called', 'pakki', 'round', 'pure', 'round'], ['more', 'police', 'officers', 'deployed', 'clashes', 'reported', 'candle', 'lit', 'vigil'], ['when', 'possible', 'often', 'follows', 'edges', 'various', 'vegetation', 'catch', 'prey', 'surprise'], ['versace', 'unique', 'among', 'italian', 'fashion', 'houses', 'due', 'frequent', 'use', 'celebrity', 'face', 'house', 'advertisements'], ['according', 'henri', 'zerner', 'work', 'freedom', 'immediacy', 'equivalent', 'renaissance', 'printmaking'], ['the', 'court', 'hearings', 'open', 'public'], ['after', 'completing', 'phd', 'stayed', 'berkeley', 'teach', 'year', 'left', 'clear', 'could', 'pursue', 'vision'], []]\n",
            "Vocabulary size:  137\n",
            "Vocabulary {'the': 1, 'to': 2, 'in': 3, 'and': 4, 'a': 5, 'that': 6, 'of': 7, 's': 8, 'he': 9, 'is': 10, \"'\": 11, 'his': 12, 'had': 13, 'this': 14, 'gives': 15, 'some': 16, 'her': 17, 'called': 18, 'round': 19, 'were': 20, 'no': 21, 'when': 22, 'it': 23, 'its': 24, 'for': 25, 'showing': 26, 'even': 27, 'modern': 28, 'warfare': 29, 'dilapidated': 30, 'fortifications': 31, 'still': 32, 'defensive': 33, 'usefulness': 34, 'celtic': 35, 'finally': 36, 'cemented': 37, 'permanent': 38, 'home': 39, 'would': 40, 'see': 41, 'huge': 42, 'success': 43, 'present': 44, 'day': 45, 'shuji': 46, 'pills': 47, 'saying': 48, 'chise': 49, 'needs': 50, 'them': 51, 'so': 52, 'weapon': 53, 'side': 54, 'won': 55, '’': 56, 't': 57, 'take': 58, 'over': 59, 'later': 60, 'much': 61, 'needed': 62, 'maintenance': 63, 'areas': 64, 'where': 65, 'trio': 66, 'trail': 67, 'hand': 68, 'pakki': 69, 'pure': 70, 'more': 71, 'than': 72, 'police': 73, 'officers': 74, 'deployed': 75, 'but': 76, 'clashes': 77, 'reported': 78, 'candle': 79, 'lit': 80, 'vigil': 81, 'possible': 82, 'often': 83, 'follows': 84, 'edges': 85, 'various': 86, 'vegetation': 87, 'catch': 88, 'prey': 89, 'by': 90, 'surprise': 91, 'versace': 92, 'unique': 93, 'among': 94, 'italian': 95, 'fashion': 96, 'houses': 97, 'due': 98, 'frequent': 99, 'use': 100, 'celebrity': 101, 'face': 102, 'house': 103, 'advertisements': 104, 'according': 105, 'henri': 106, 'zerner': 107, 'work': 108, 'has': 109, 'freedom': 110, 'immediacy': 111, 'have': 112, 'equivalent': 113, 'renaissance': 114, 'printmaking': 115, 'court': 116, 'hearings': 117, 'are': 118, 'open': 119, 'public': 120, 'after': 121, 'completing': 122, 'phd': 123, 'stayed': 124, 'on': 125, 'at': 126, 'berkeley': 127, 'teach': 128, 'year': 129, 'left': 130, 'was': 131, 'clear': 132, 'could': 133, 'not': 134, 'pursue': 135, 'vision': 136, 'there': 137}\n",
            "Index to word dict {1: 'the', 2: 'to', 3: 'in', 4: 'and', 5: 'a', 6: 'that', 7: 'of', 8: 's', 9: 'he', 10: 'is', 11: \"'\", 12: 'his', 13: 'had', 14: 'this', 15: 'gives', 16: 'some', 17: 'her', 18: 'called', 19: 'round', 20: 'were', 21: 'no', 22: 'when', 23: 'it', 24: 'its', 25: 'for', 26: 'showing', 27: 'even', 28: 'modern', 29: 'warfare', 30: 'dilapidated', 31: 'fortifications', 32: 'still', 33: 'defensive', 34: 'usefulness', 35: 'celtic', 36: 'finally', 37: 'cemented', 38: 'permanent', 39: 'home', 40: 'would', 41: 'see', 42: 'huge', 43: 'success', 44: 'present', 45: 'day', 46: 'shuji', 47: 'pills', 48: 'saying', 49: 'chise', 50: 'needs', 51: 'them', 52: 'so', 53: 'weapon', 54: 'side', 55: 'won', 56: '’', 57: 't', 58: 'take', 59: 'over', 60: 'later', 61: 'much', 62: 'needed', 63: 'maintenance', 64: 'areas', 65: 'where', 66: 'trio', 67: 'trail', 68: 'hand', 69: 'pakki', 70: 'pure', 71: 'more', 72: 'than', 73: 'police', 74: 'officers', 75: 'deployed', 76: 'but', 77: 'clashes', 78: 'reported', 79: 'candle', 80: 'lit', 81: 'vigil', 82: 'possible', 83: 'often', 84: 'follows', 85: 'edges', 86: 'various', 87: 'vegetation', 88: 'catch', 89: 'prey', 90: 'by', 91: 'surprise', 92: 'versace', 93: 'unique', 94: 'among', 95: 'italian', 96: 'fashion', 97: 'houses', 98: 'due', 99: 'frequent', 100: 'use', 101: 'celebrity', 102: 'face', 103: 'house', 104: 'advertisements', 105: 'according', 106: 'henri', 107: 'zerner', 108: 'work', 109: 'has', 110: 'freedom', 111: 'immediacy', 112: 'have', 113: 'equivalent', 114: 'renaissance', 115: 'printmaking', 116: 'court', 117: 'hearings', 118: 'are', 119: 'open', 120: 'public', 121: 'after', 122: 'completing', 123: 'phd', 124: 'stayed', 125: 'on', 126: 'at', 127: 'berkeley', 128: 'teach', 129: 'year', 130: 'left', 131: 'was', 132: 'clear', 133: 'could', 134: 'not', 135: 'pursue', 136: 'vision', 137: 'there'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:96: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RL7sY5WQwsus"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWTuhQaFwxIX",
        "outputId": "23e269eb-b153-44ce-a11b-7e936d2b32ae"
      },
      "source": [
        "# w2v.train(epochs=epochs)\n",
        "# # print('-----------W1-------------')\n",
        "# # print(w2v.W1)\n",
        "# # print('-----------b1-------------')\n",
        "# # print(w2v.b1)\n",
        "\n",
        "# print(w2v.check_subtract_prop('bangladesh', 'dhaka', 'delhi'))\n",
        "# # print(w2v.vectorized(6))\n",
        "# print(w2v.word_with_closest_distance('dhaka'))\n",
        "# print(w2v.word_with_closest_distance('delhi'))\n",
        "\n",
        "import time\n",
        "start = time.process_time()  \n",
        "w2v_cbow.train_using_numpy(epochs=epochs)\n",
        "print('CBOW training time: ', time.process_time() - start)\n",
        "\n",
        "start = time.process_time()  \n",
        "w2v_skip_gram.train_using_numpy(epochs=epochs)\n",
        "print('Skip-Gram training time: ', time.process_time() - start)\n",
        "# print('-----------W1-------------')\n",
        "# print(w2v.W1)\n",
        "# print('-----------b1-------------')\n",
        "# print(w2v.b1)\n",
        "\n",
        "# print('vector of dhaka')\n",
        "# print(w2v.get_vector_from_word('dhaka'))\n",
        "# print('vector of delhi')\n",
        "# print(w2v.get_vector_from_word('delhi'))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 0 LOSS: 526.3418448363464\n",
            "EPOCH: 1000 LOSS: 2.4199657962338783\n",
            "EPOCH: 2000 LOSS: 1.8917189020410827\n",
            "EPOCH: 3000 LOSS: 1.7350717128037338\n",
            "EPOCH: 4000 LOSS: 1.6588123364397216\n",
            "EPOCH: 5000 LOSS: 1.613166417727868\n",
            "EPOCH: 6000 LOSS: 1.5825196465739282\n",
            "EPOCH: 7000 LOSS: 1.5603707689693191\n",
            "EPOCH: 8000 LOSS: 1.5435221115454585\n",
            "EPOCH: 9000 LOSS: 1.5302152783129888\n",
            "CBOW training time:  106.01523225099999\n",
            "EPOCH: 0 LOSS: 2611.380014715372\n",
            "EPOCH: 1000 LOSS: 900.2532368443578\n",
            "EPOCH: 2000 LOSS: 890.0748733029251\n",
            "EPOCH: 3000 LOSS: 884.404156998295\n",
            "EPOCH: 4000 LOSS: 890.7518327180584\n",
            "EPOCH: 5000 LOSS: 889.3032163637497\n",
            "EPOCH: 6000 LOSS: 889.1091151340385\n",
            "EPOCH: 7000 LOSS: 884.0374618899765\n",
            "EPOCH: 8000 LOSS: 884.0140723242994\n",
            "EPOCH: 9000 LOSS: 879.8940682801234\n",
            "Skip-Gram training time:  142.071141512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "vVZTtLSDScAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_vectors(w2v_cbow.W1)"
      ],
      "metadata": {
        "id": "clhcpgN-SzPA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "outputId": "4f6d061f-2be5-4efe-abab-7b27fdf5df9b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'the': 1, 'to': 2, 'in': 3, 'and': 4, 'a': 5, 'that': 6, 'of': 7, 's': 8, 'he': 9, 'is': 10, \"'\": 11, 'his': 12, 'had': 13, 'this': 14, 'gives': 15, 'some': 16, 'her': 17, 'called': 18, 'round': 19, 'were': 20, 'no': 21, 'when': 22, 'it': 23, 'its': 24, 'for': 25, 'showing': 26, 'even': 27, 'modern': 28, 'warfare': 29, 'dilapidated': 30, 'fortifications': 31, 'still': 32, 'defensive': 33, 'usefulness': 34, 'celtic': 35, 'finally': 36, 'cemented': 37, 'permanent': 38, 'home': 39, 'would': 40, 'see': 41, 'huge': 42, 'success': 43, 'present': 44, 'day': 45, 'shuji': 46, 'pills': 47, 'saying': 48, 'chise': 49, 'needs': 50, 'them': 51, 'so': 52, 'weapon': 53, 'side': 54, 'won': 55, '’': 56, 't': 57, 'take': 58, 'over': 59, 'later': 60, 'much': 61, 'needed': 62, 'maintenance': 63, 'areas': 64, 'where': 65, 'trio': 66, 'trail': 67, 'hand': 68, 'pakki': 69, 'pure': 70, 'more': 71, 'than': 72, 'police': 73, 'officers': 74, 'deployed': 75, 'but': 76, 'clashes': 77, 'reported': 78, 'candle': 79, 'lit': 80, 'vigil': 81, 'possible': 82, 'often': 83, 'follows': 84, 'edges': 85, 'various': 86, 'vegetation': 87, 'catch': 88, 'prey': 89, 'by': 90, 'surprise': 91, 'versace': 92, 'unique': 93, 'among': 94, 'italian': 95, 'fashion': 96, 'houses': 97, 'due': 98, 'frequent': 99, 'use': 100, 'celebrity': 101, 'face': 102, 'house': 103, 'advertisements': 104, 'according': 105, 'henri': 106, 'zerner': 107, 'work': 108, 'has': 109, 'freedom': 110, 'immediacy': 111, 'have': 112, 'equivalent': 113, 'renaissance': 114, 'printmaking': 115, 'court': 116, 'hearings': 117, 'are': 118, 'open': 119, 'public': 120, 'after': 121, 'completing': 122, 'phd': 123, 'stayed': 124, 'on': 125, 'at': 126, 'berkeley': 127, 'teach': 128, 'year': 129, 'left': 130, 'was': 131, 'clear': 132, 'could': 133, 'not': 134, 'pursue': 135, 'vision': 136, 'there': 137}\n",
            "{'the': 1, 'to': 2, 'in': 3, 'and': 4, 'a': 5, 'that': 6, 'of': 7, 's': 8, 'he': 9, 'is': 10, \"'\": 11, 'his': 12, 'had': 13, 'this': 14, 'gives': 15, 'some': 16, 'her': 17, 'called': 18, 'round': 19, 'were': 20, 'no': 21, 'when': 22, 'it': 23, 'its': 24, 'for': 25, 'showing': 26, 'even': 27, 'modern': 28, 'warfare': 29, 'dilapidated': 30, 'fortifications': 31, 'still': 32, 'defensive': 33, 'usefulness': 34, 'celtic': 35, 'finally': 36, 'cemented': 37, 'permanent': 38, 'home': 39, 'would': 40, 'see': 41, 'huge': 42, 'success': 43, 'present': 44, 'day': 45, 'shuji': 46, 'pills': 47, 'saying': 48, 'chise': 49, 'needs': 50, 'them': 51, 'so': 52, 'weapon': 53, 'side': 54, 'won': 55, '’': 56, 't': 57, 'take': 58, 'over': 59, 'later': 60, 'much': 61, 'needed': 62, 'maintenance': 63, 'areas': 64, 'where': 65, 'trio': 66, 'trail': 67, 'hand': 68, 'pakki': 69, 'pure': 70, 'more': 71, 'than': 72, 'police': 73, 'officers': 74, 'deployed': 75, 'but': 76, 'clashes': 77, 'reported': 78, 'candle': 79, 'lit': 80, 'vigil': 81, 'possible': 82, 'often': 83, 'follows': 84, 'edges': 85, 'various': 86, 'vegetation': 87, 'catch': 88, 'prey': 89, 'by': 90, 'surprise': 91, 'versace': 92, 'unique': 93, 'among': 94, 'italian': 95, 'fashion': 96, 'houses': 97, 'due': 98, 'frequent': 99, 'use': 100, 'celebrity': 101, 'face': 102, 'house': 103, 'advertisements': 104, 'according': 105, 'henri': 106, 'zerner': 107, 'work': 108, 'has': 109, 'freedom': 110, 'immediacy': 111, 'have': 112, 'equivalent': 113, 'renaissance': 114, 'printmaking': 115, 'court': 116, 'hearings': 117, 'are': 118, 'open': 119, 'public': 120, 'after': 121, 'completing': 122, 'phd': 123, 'stayed': 124, 'on': 125, 'at': 126, 'berkeley': 127, 'teach': 128, 'year': 129, 'left': 130, 'was': 131, 'clear': 132, 'could': 133, 'not': 134, 'pursue': 135, 'vision': 136, 'there': 137}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_vectors(w2v_skip_gram.W1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "VoJWW94MihYq",
        "outputId": "b92d4a44-c7c6-4750-d971-4a6fdceea0e1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'the': 1, 'to': 2, 'in': 3, 'and': 4, 'a': 5, 'that': 6, 'of': 7, 's': 8, 'he': 9, 'is': 10, \"'\": 11, 'his': 12, 'had': 13, 'this': 14, 'gives': 15, 'some': 16, 'her': 17, 'called': 18, 'round': 19, 'were': 20, 'no': 21, 'when': 22, 'it': 23, 'its': 24, 'for': 25, 'showing': 26, 'even': 27, 'modern': 28, 'warfare': 29, 'dilapidated': 30, 'fortifications': 31, 'still': 32, 'defensive': 33, 'usefulness': 34, 'celtic': 35, 'finally': 36, 'cemented': 37, 'permanent': 38, 'home': 39, 'would': 40, 'see': 41, 'huge': 42, 'success': 43, 'present': 44, 'day': 45, 'shuji': 46, 'pills': 47, 'saying': 48, 'chise': 49, 'needs': 50, 'them': 51, 'so': 52, 'weapon': 53, 'side': 54, 'won': 55, '’': 56, 't': 57, 'take': 58, 'over': 59, 'later': 60, 'much': 61, 'needed': 62, 'maintenance': 63, 'areas': 64, 'where': 65, 'trio': 66, 'trail': 67, 'hand': 68, 'pakki': 69, 'pure': 70, 'more': 71, 'than': 72, 'police': 73, 'officers': 74, 'deployed': 75, 'but': 76, 'clashes': 77, 'reported': 78, 'candle': 79, 'lit': 80, 'vigil': 81, 'possible': 82, 'often': 83, 'follows': 84, 'edges': 85, 'various': 86, 'vegetation': 87, 'catch': 88, 'prey': 89, 'by': 90, 'surprise': 91, 'versace': 92, 'unique': 93, 'among': 94, 'italian': 95, 'fashion': 96, 'houses': 97, 'due': 98, 'frequent': 99, 'use': 100, 'celebrity': 101, 'face': 102, 'house': 103, 'advertisements': 104, 'according': 105, 'henri': 106, 'zerner': 107, 'work': 108, 'has': 109, 'freedom': 110, 'immediacy': 111, 'have': 112, 'equivalent': 113, 'renaissance': 114, 'printmaking': 115, 'court': 116, 'hearings': 117, 'are': 118, 'open': 119, 'public': 120, 'after': 121, 'completing': 122, 'phd': 123, 'stayed': 124, 'on': 125, 'at': 126, 'berkeley': 127, 'teach': 128, 'year': 129, 'left': 130, 'was': 131, 'clear': 132, 'could': 133, 'not': 134, 'pursue': 135, 'vision': 136, 'there': 137}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zb1le_rOQVmi"
      },
      "source": [
        "# Previous Test ('Dhaka is the capital of Bangladesh. Delhi is the capital of India. Paris is the capital of France.')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGNsh5pn8inM"
      },
      "source": [
        "# print('CBOW Results:')\n",
        "# print('bangladesh - dhaka + france = ', w2v_cbow.check_subtract_prop('bangladesh', 'dhaka', 'paris'))\n",
        "# print('bangladesh - dhaka + france = ', w2v_cbow.check_subtract_prop('bangladesh', 'dhaka', 'delhi'))\n",
        "# print('bangladesh - dhaka + france = ', w2v_cbow.check_subtract_prop('paris', 'france', 'dhaka'))\n",
        "# print('bangladesh - dhaka + france = ', w2v_cbow.check_subtract_prop('france', 'paris', 'bangladesh'))\n",
        "# # print(w2v_cbow.W1)\n",
        "# print('dhaka -> ', w2v_cbow.word_with_closest_distance('dhaka'))\n",
        "# print('delhi -> ', w2v_cbow.word_with_closest_distance('delhi'))\n",
        "# print('paris -> ', w2v_cbow.word_with_closest_distance('paris'))\n",
        "# print('---------------------------------')\n",
        "\n",
        "# print('Skip Gram Results:')\n",
        "# print('bangladesh - dhaka + france = ', w2v_skip_gram.check_subtract_prop('bangladesh', 'dhaka', 'france'))\n",
        "# print('bangladesh - dhaka + paris = ', w2v_skip_gram.check_subtract_prop('bangladesh', 'dhaka', 'paris'))\n",
        "# print('bangladesh - dhaka + delhi = ', w2v_skip_gram.check_subtract_prop('bangladesh', 'dhaka', 'delhi'))\n",
        "# print('paris - france + dhaka = ', w2v_skip_gram.check_subtract_prop('paris', 'france', 'dhaka'))\n",
        "# print('france - paris + bangladesh = ', w2v_skip_gram.check_subtract_prop('france', 'paris', 'bangladesh'))\n",
        "# # print(w2v_cbow.W1)\n",
        "# print('dhaka -> ', w2v_skip_gram.word_with_closest_distance('dhaka'))\n",
        "# print('delhi -> ', w2v_skip_gram.word_with_closest_distance('delhi'))\n",
        "# print('paris -> ', w2v_skip_gram.word_with_closest_distance('paris'))\n",
        "# # print(w2v_skip_gram.W1)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT9DQn2wXzMi"
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": []
    }
  ]
}